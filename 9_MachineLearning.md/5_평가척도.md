# 평가지표
- **MAE** : Mean Absolute Error이며 실제값과 예측값의 차이를 절댓값으로 변환해 평균한 것
- **MSE** : Mean Squared Error이며 실제 값과 예측값의 차이를 제곱해 평균한 것
- **MSLE** : MSE에 로그를 적용한 것
- **RMSE** : MSE에 루트를 씌운 것
- **RMSLE** : MLSE에 로그를 적용한 것
=> 오류값 작을수록 좋음
- **R^2** : 분산 기반으로 예측 성능을 평가
=> 1에 가까울 수록 예측 정확도가 높음

## 실습
### LinearRegression
- 방법1
```python
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score

##########데이터 로드
x_data = np.array([
    [2, 1],
    [3, 2],
    [3, 4],
    [5, 5],
    [7, 5],
    [2, 5],
    [8, 9],
    [9, 10],
    [6, 12],
    [9, 2],
    [6, 10],
    [2, 4]
])
y_data = np.array([3, 5, 7, 10, 12, 7, 13, 13, 12, 13, 12, 6])

# 데이터 분석
pass

# 데이터 전처리
x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, random_state=777)

# 모델 생성
model = LinearRegression()

# 모델 학습
model.fit(x_train, y_train)

# 모델 검증
y_predict = model.predict(x_test)
print(model.score(x_test,y_test))
print(r2_score(y_test, y_predict)) #0.8526379440119077

# 모델 예측
x_test = np.array([
    [4, 6]
])

y_predict = model.predict(x_test)

print(y_predict[0]) #8.279504382440336
```

- 방법2
```python
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_log_error

# 데이터 로드
x_data = np.array([
    [2, 1],
    [3, 2],
    [3, 4],
    [5, 5],
    [7, 5],
    [2, 5],
    [8, 9],
    [9, 10],
    [6, 12],
    [9, 2],
    [6, 10],
    [2, 4]
])
y_data = np.array([3, 5, 7, 10, 12, 7, 13, 13, 12, 13, 12, 6])

# 데이터 분석
pass

# 데이터 전처리
x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, random_state=777)

# 모델 생성
model = LinearRegression()

# 모델 학습
model.fit(x_train, y_train)

# 모델 검증
y_predict = model.predict(x_test)

print('R2_train',model.score(x_train, y_train)) 
print('R2_test',model.score(x_test, y_test)) 
print('--------------------------------')
print('R2_test',r2_score(y_test, y_predict)) #0.8526379440119077
print('MSE',mean_squared_error(y_test, y_predict)) #1.694663643863061
print('RMSE',mean_squared_error(y_test,y_predict,squared=False))
print('MAE',mean_absolute_error(y_test, y_predict)) #1.010718237138116
print('MSLE',mean_squared_log_error(y_test, y_predict)) #0.05501235501698321

# 모델 예측
x_real = np.array([
    [4, 6]
])

y_pred = model.predict(x_real)

# print(y_predict[0]) #8.359902268117278
```

- 방법3
```python
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_log_error

def evaluate_reg_all(y_test, y_predict):
    MSE = mean_squared_error(y_test,y_predict,squared=True)
    RMSE = mean_squared_error(y_test,y_predict,squared=False)  # squared=False : RMSE
    MAE = mean_absolute_error(y_test,y_predict)
    R2 = r2_score(y_test,y_predict)
    
    print(f'MSE: {MSE:.3f}, RMSE: {RMSE:.3F}, MAE: {MAE:.3F}, R^2: {R2:.3F}')
```
```python
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_log_error

# 데이터 로드
x_data = np.array([
    [2, 1],
    [3, 2],
    [3, 4],
    [5, 5],
    [7, 5],
    [2, 5],
    [8, 9],
    [9, 10],
    [6, 12],
    [9, 2],
    [6, 10],
    [2, 4]
])
y_data = np.array([3, 5, 7, 10, 12, 7, 13, 13, 12, 13, 12, 6])

# 데이터 분석
pass

# 데이터 전처리
x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, random_state=777)

# 모델 생성
model = LinearRegression()

# 모델 학습
model.fit(x_train, y_train)

# 모델 검증
y_predict = model.predict(x_test)
evaluate_reg_all(y_test, y_predict) 


# 모델 예측
x_real = np.array([
    [4, 6]
])

y_pred = model.predict(x_real)

# print(y_predict[0]) #8.359902268117278
```